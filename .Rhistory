str(y)
y <- c(6,5,5,3,4,5,6,7)
str(y)
tr
y <- sample(1:6, 100)
y <- sample(1:6, 100, replace = T)
diff(by(y, tr, mean))
# install a package
!require("tidyerse")
# install a package
!require("tidyverse")
69+28.95
47.5+20.75
library(collostructions)
?collex.distst
?collex.dist
set.seed(123)
library(zipfR)
set.seed(123)
d <- data.frame(cxn = sample(c("A", "B"), 100, replace = T),
freq1 = rnorm(100, mean = 50, sd = 20),
freq2 = rnorm(100, mean = 50, sd = 20))
d
set.seed(123)
d <- data.frame(cxn = sample(c("A", "B"), 100, replace = T),
freq1 = round(rnorm(100, mean = 50, sd = 20)),
freq2 = round(rnorm(100, mean = 50, sd = 20)))
d
collex.dist(d)
subset(collex.dist(d), SIGNIF != "ns")
d2 <- d
d2$freq1 <- d2$freq1*10
d2$freq2 <- d2$freq2*10
subset(collex.dist(d), SIGNIF != "ns")
head(subset(collex.dist(d), SIGNIF != "ns"))
head(subset(collex.dist(d), SIGNIF != "ns"))
head(subset(collex.dist(d2), SIGNIF != "ns"))
head(subset(collex.dist(d), SIGNIF != "ns"))
head(subset(collex.dist(d2), SIGNIF != "ns"))
fion <- readxl::read_xlsx("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/fion_wordlist.xlsx")
View(fion)
silvie <- readxl::read_xlsx("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist02.xlsx")
View(silvie)
sum(fion$n)
sum(fion$n_CHI)
sum(fion$n_CDS)
sum(silvie$n_CHI)
sum(silvie$n_CDS)
sum(fion$n_CHI)+sum(fion$n_CDS)+sum(silvie$n_CHI)+sum(silvie$n_CDS)
library(tidyverse)
library(readxl)
?readxl::excel_sheets
excel_sheets("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/fion_wordlist.xlsx")
length(excel_sheets("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/fion_wordlist.xlsx"))
fion$n_CHI+fion$n_CDS
sum(fion$n_CHI)+sum(fion$n_CDS)
for(i in 1:21) {
fion <- read_xlsx("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/fion_wordlist.xlsx", sheet = i)
if(i == 1) {
n_all <- sum(fion$n_CHI)+sum(fion$n_CDS)
} else {
n_all <- n_all + sum(fion$n_CHI)+sum(fion$n_CDS)
}
}
length(excel_sheets("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist.xlsx"))
length(excel_sheets("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist02.xlsx"))
for(i in 1:10) {
silvie <- read_xlsx("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist02.xlsx", sheet = i)
if(i == 1) {
n_all <- sum(silvie$n_CHI)+sum(silvie$n_CDS)
} else {
n_all <- n_all + sum(silvie$n_CHI)+sum(silvie$n_CDS)
}
}
library(tidyverse)
library(readxl)
length(excel_sheets("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/fion_wordlist.xlsx"))
length(excel_sheets("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist02.xlsx"))
for(i in 1:21) {
fion <- read_xlsx("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/fion_wordlist.xlsx", sheet = i)
if(i == 1) {
n_all <- sum(fion$n_CHI)+sum(fion$n_CDS)
} else {
n_all <- n_all + sum(fion$n_CHI)+sum(fion$n_CDS)
}
}
for(i in 1:10) {
silvie <- read_xlsx("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist02.xlsx", sheet = i)
if(i == 1) {
n_all_silvie <- sum(silvie$n_CHI)+sum(silvie$n_CDS)
} else {
n_all_silvie <- n_all + sum(silvie$n_CHI)+sum(silvie$n_CDS)
}
}
n_all+n_all_silvie
f <- list.files("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist", full.names = T)
f <- list.files("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist", full.names = T)
for(i in 1:length(f)) {
silvie <- read_xlsx(f[i])
if(i == 1) {
n_all_silvie <- sum(silvie$n_CHI)+sum(silvie$n_CDS)
} else {
n_all_silvie <- n_all + sum(silvie$n_CHI)+sum(silvie$n_CDS)
}
}
n_all+n_all_silvie
f <- list.files("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/lily_wordlist", full.names = T)
for(i in 1:length(f)) {
lily <- read_xlsx(f[i])
if(i == 1) {
n_all_lily <- sum(lily$n_CHI)+sum(lily$n_CDS)
} else {
n_all_lily <- n_all + sum(lily$n_CHI)+sum(lily$n_CDS)
}
}
n_all+n_all_silvie+n_all_lily
install.packages("quanteda")
library(gutenbergr)
gutenberg_languages
filter(gutenberg_languages, language=="de")
library(tidyverse)
gl <- gutenberg_languages
filter(gl, language=="de")
glde <- filter(gl, language=="de")
gutenberg_metadata
gutenberg_metadata
586.2*6
586.2*9
586.2*6
586.2*8
707.62*6
4689.6+4245.72
544.33*4
544.33*5
544.33*6
544.33*4
544.33*5
3000/707.62
707.62*4
707.62*4.5
10+6+2+8+18
# relative Bestehensgrenze:
117.5*0.78
# Punktverteilung
seq(91, 160, length.out = 11)
127+139+148+145+119+112
790/6
0.78*131.66
60+88+69
217/3
setwd("~/sciebo/Projekte/modifiers/DECOW/osf_GM")
# load packages
# install.packages("https://sfla.ch/wp-content/uploads/2021/02/collostructions_0.2.0.tar.gz", repos = NULL)
library(collostructions) # available at sfla.ch
library(concordances)
library(tidyverse)
library(data.table)
library(ggraph)
library(igraph)
library(networkD3)
library(DT)
library(readxl)
library(vroom)
library(corrplot)
# list of files
f <- list.files(pattern = "xml")
# get queries from concordance file:
sapply(1:length(f), function(i) trimws(gsub("<query>|</query>", "", readLines(f[i], n = 7)[6])))
fuenk <- getNSE("ein_em_Fuenkchen_ADJ_N.xml", xml = T, tags = T, context_tags = F, verbose = T)
fuenk_zu <- getNSE("ein_em_Fuenkchen_zu.xml", xml = T, tags = T, context_tags = F, verbose = T)
tack_zack <- getNSE("ein_enm_Tacken_Zacken_N_ADJ.xml", xml = T, context_tags = F)
tack_zack_zu <- getNSE("ein_enm_Tacken_Zacken_zu.xml", xml = T, context_tags = F)
handvoll <- getNSE("eine_r_Handvoll_ADJ_N.xml", xml = T, context_tags = F, tags = T)
idee <- getNSE("eine_r_Idee_ADJ_N.xml", xml = T, context_tags = F, tags = T)
idee_zu <- getNSE("eine_r_Idee_zu_ADJ.xml", xml = T, context_tags = F, tags = T)
tick <- getNSE("ein_enm_Tick_ADJ_N.xml", xml = T, context_tags = F, tags = T)
tick_zu <- getNSE("ein_enm_Tick_zu.xml", xml = T, context_tags = F, tags = T)
bisschen <- fread("ein_bisschen_adj_n_lemma_frequency_list.txt", col.names = c("Token", "Freq", "bla"))
bisschen_zu <- fread("ein_bisschen_zu_adj_frequency_list.txt", col.names = c("Token", "Freq", "bla"))
hauch <- getNSE("ein_enm_Hauch_ADJ_N.xml", xml = T, context_tags = F, tags = T)
hauch_zu <- getNSE("ein_enm_Hauch_zu.xml", xml = T, context_tags = F, tags = T)
spur <- getNSE("eine_r_Spur_N_Adj.xml", xml = T, context_tags = F, tags = T)
spur_zu <- getNSE("eine_r_Spur_zu_ADJ.xml", xml = T, context_tags = F, tags = T)
quaentchen <- getNSE("ein_emn_Quäentchen_N_ADJ_V.xml", xml = T, context_tags = F, tags = T)
quaentchen_zu <- getNSE("ein_enm_Quäentchen_zu.xml", xml = T, context_tags = F, tags = T)
# function for removing duplicates -----------
remove_duplicates <- function(df) {
x <- which(duplicated(df$Left) &
duplicated(df$Key) &
duplicated(df$Right))
if(length(x) > 0) {
df <- df[-x,]
}
return(df)
}
# remove "unknown" lemma from "bisschen" dataframe
bisschen <- bisschen[grep("(unknown)", bisschen$Token, invert = T),]
bisschen_zu <- bisschen_zu[grep("(unknown)", bisschen_zu$Token, invert = T),]
# get modified nouns and adjectives in
# "bisschen" dataframe
bisschen$Lemma <- last_left(bisschen$Token, n = 1)
bisschen_zu$Lemma <- last_left(bisschen_zu$Token, n = 1)
# remove empty column from bisschen
bisschen <- bisschen[,c(1,2,4)]
bisschen_zu <- bisschen_zu[,c(1,2,4)]
# backup copy
bisschen_backup <- bisschen
bisschen_zu_backup <- bisschen_zu
# some are duplicated, so we have to sum them up:
bisschen <- bisschen %>% group_by(Lemma) %>% summarise(
Freq = sum(Freq)
)
bisschen_zu <- bisschen_zu %>% group_by(Lemma) %>% summarise(
Freq = sum(Freq)
)
# remove duplicates
idee <- remove_duplicates(idee)
tick <- remove_duplicates(tick)
handvoll <- remove_duplicates(handvoll)
tack_zack <- remove_duplicates(tack_zack)
fuenk <- remove_duplicates(fuenk)
hauch <- remove_duplicates(hauch)
spur <- remove_duplicates(spur)
idee_zu <- remove_duplicates(idee_zu)
tick_zu <- remove_duplicates(tick_zu)
tack_zack_zu <- remove_duplicates(tack_zack_zu)
fuenk_zu <- remove_duplicates(fuenk_zu)
hauch_zu <- remove_duplicates(hauch_zu)
spur_zu <- remove_duplicates(spur_zu)
quaentchen <- remove_duplicates(quaentchen)
quaentchen_zu <- remove_duplicates(quaentchen_zu)
# combine "zu" and "normal" ones:
idee <- rbind(mutate(idee), cxn_type = "ADJ_N",
mutate(idee_zu), cxn_type = "zu_ADJ")
spur <- rbind(mutate(spur), cxn_type = "ADJ_N",
mutate(spur_zu), cxn_type = "zu_ADJ")
fuenk <- rbind(mutate(fuenk), cxn_type = "ADJ_N",
mutate(fuenk_zu), cxn_type = "zu_ADJ")
spur <- rbind(mutate(spur), cxn_type = "ADJ_N",
mutate(spur_zu), cxn_type = "zu_ADJ")
tack_zack <- rbind(mutate(tack_zack), cxn_type = "ADJ_N",
mutate(tack_zack_zu), cxn_type = "zu_ADJ")
tick <- rbind(mutate(tick), cxn_type = "ADJ_N",
mutate(tick_zu), cxn_type = "zu_ADJ")
hauch <- rbind(mutate(hauch), cxn_type = "ADJ_N",
mutate(hauch_zu), cxn_type = "zu_ADJ")
quaentchen <- rbind(mutate(quaentchen), cxn_type = "ADJ_N",
mutate(quaentchen_zu), cxn_type = "zu_ADJ")
bisschen <- rbind(mutate(bisschen), cxn_type = "ADJ_N",
mutate(bisschen_zu), cxn_type = "zu_ADJ")
# add lemma column
idee$Lemma <- last_left(idee, Tag3_Key, 1)
tick$Lemma <- last_left(tick, Tag3_Key, 1)
fuenk$Lemma <- last_left(fuenk, Tag3_Key, 1)
tack_zack$Lemma <- last_left(tack_zack, Tag3_Key, 1)
handvoll$Lemma <- last_left(handvoll, Tag3_Key, 1)
spur$Lemma <- last_left(spur, Tag3_Key, 1)
hauch$Lemma <- last_left(hauch, Tag3_Key, 1)
quaentchen$Lemma <- last_left(quaentchen, Tag3_Key, 1)
# import data
idee <- read_xlsx("idee_for_anno.xlsx")
hauch <- read_xlsx("hauch_for_anno.xlsx")
spur <- read_xlsx("spur_for_anno.xlsx")
# remove false hits
idee <- filter(idee, keep == "y")
hauch <- filter(hauch, Modifier == "y")
spur <- filter(spur, Modifier == "y")
fuenk <- fuenk[grep("^V.*", last_left(fuenk$Tag2_Key, n = 1), invert = T),]
hauch <- hauch[grep("^V.*", last_left(hauch$Tag2_Key, n = 1), invert = T),]
tick <- tick[grep("^V.*", last_left(tick$Tag2_Key, n = 1), invert = T),]
quaentchen <- quaentchen[grep("^V.*", last_left(quaentchen$Tag2_Key, n = 1), invert = T),]
tack_zack <- tack_zack[grep("^V.*", last_left(tack_zack$Tag2_Key, n = 1), invert = T),]
tick <- tick[grep("^V.*", last_left(tick$Tag2_Key, n = 1), invert = T),]
# function for getting the distribution:
get_distro <- function(vec) {
x <- gsub("(?<=.).*", "", last_left(trimws(vec), n = 1), perl = T) %>% table
y <- x[which(names(x) %in% c("A", "N", "V"))]
y <- c(y, "other" = sum(x[which(!names(x) %in% c("A", "N", "V"))]))
return(y)
}
# function for finding comparatives:
get_compar <- function(df) {
# find comparatives
find_comparatives <- which(grepl("ADJ.*", last_left(df$Tag2_Key, n = 1)) &
grepl("er(e|es|en)?$", trimws(df$Key)))
# add to df
df$comparative <- sapply(1:nrow(df), function(i) ifelse(i %in% find_comparatives, "yes", "no"))
return(table(df$comparative))
}
# get "zu ADJ"
get_zu <- function(df) {
return(length(which(sapply(1:nrow(df), function(i) unlist(strsplit(df$Key[i], " "))[3])=="zu")))
}
# get POS distributions
get_distro(fuenk$Tag2_Key) %>% as.data.frame %>% t()
distro <- bind_rows(
get_distro(fuenk$Tag2_Key),
get_distro(handvoll$Tag2_Key),
get_distro(idee$Tag2_Key),
get_distro(hauch$Tag2_Key),
get_distro(quaentchen$Tag2_Key),
get_distro(spur$Tag2_Key),
get_distro(tack_zack[grepl("Tacken", tack_zack$Key, ignore.case = T),]$Tag2_Key),
get_distro(tack_zack[grepl("Zacken", tack_zack$Key, ignore.case = T),]$Tag2_Key),
get_distro(tick$Tag2_Key)
) %>% as_tibble %>% mutate(Cxn = c("Fünkchen", "Handvoll", "Idee", "Hauch", "Quäntchen", "Spur", "Tacken", "Zacken", "Tick")) %>% replace_na(list(A = 0, N = 0, V = 0))
# get comparative distributions
distro <- mutate(distro, comparatives = c(
get_compar(fuenk)[2],
get_compar(handvoll)[2],
get_compar(idee)[2],
get_compar(hauch)[2],
get_compar(quaentchen)[2],
get_compar(spur)[2],
get_compar(tack_zack[grepl("Tacken", tack_zack$Key, ignore.case = T),])[2],
get_compar(tack_zack[grepl("Zacken", tack_zack$Key, ignore.case = T),])[2],
get_compar(tick)[2]
)) %>% replace_na(list(comparatives = 0))
# zu...
distro <- mutate(distro, zu = c(
get_zu(fuenk),
get_zu(handvoll),
get_zu(idee),
get_zu(hauch),
get_zu(quaentchen),
get_zu(spur),
get_zu(tack_zack[grepl("Tacken", tack_zack$Key, ignore.case = T),]),
get_zu(tack_zack[grepl("Zacken", tack_zack$Key, ignore.case = T),]),
get_zu(tick)
))
# column with comparatives and "zu" in ADJ column
distro$ADJ <- paste0(distro$A, " (", distro$comparatives, "/", distro$zu, ")")
distro <- rename(distro, c("ADJ (comparative / excessive)" = "ADJ"))
# add column with sum total
distro$sum <- distro$A + distro$N  + distro$other
# reorder columns
distro[,c(4,2,6,3,6,5,7,8)] %>% datatable()
b_dist <- fread("ein_bisschen_adj_n_POS_frequency_list.txt", col.names = c("POS", "Freq", "bla"))
b_dist
# get pos:
b_dist$pos <- last_left(b_dist, POS, n = 1)
# coarse-grained POS
b_dist$pos1 <- ifelse(b_dist$pos %in% c("NE", "NN"), "N", "ADJ")
# tabulate
b_dist %>% group_by(pos1) %>% summarise(
Freq = sum(Freq)
)
# re-import
decow <- readRDS("decow_modifier_lemmas.Rds")
pos_tbl <- readRDS("pos_tbl.Rds")
# sum up frequencies of lemmas occuring more than once
decow_sum <- decow %>% group_by(lemma) %>% summarise(
Freq = sum(Freq)
)
# frequency tables for the different constructions
idee_tbl <- idee %>% select(Lemma) %>% table %>% as.data.frame
fuenk_tbl <- fuenk %>% select(Lemma) %>% table %>% as.data.frame
handvoll_tbl <- handvoll %>%  select(Lemma) %>% table %>% as.data.frame
tick_tbl <- tick %>%  select(Lemma) %>% table %>% as.data.frame
tack_tbl <- tack_zack[grepl("Tacken", tack_zack$Key, ignore.case = T),] %>%
select(Lemma) %>% table %>% as.data.frame
zack_tbl <- tack_zack[grepl("Zacken", tack_zack$Key, ignore.case = T),] %>%
select(Lemma) %>% table %>% as.data.frame
hauch_tbl <- hauch %>%  select(Lemma) %>% table %>% as.data.frame
spur_tbl <- spur %>%  select(Lemma) %>% table %>% as.data.frame
quaentchen_tbl <- quaentchen %>% select(Lemma) %>% table %>% as.data.frame()
colnames(idee_tbl) <- colnames(fuenk_tbl) <-
colnames(handvoll_tbl) <- colnames(tack_tbl) <-
colnames(zack_tbl) <- colnames(tick_tbl) <-
colnames(spur_tbl) <- colnames(hauch_tbl) <-
colnames(quaentchen_tbl) <-
c("lemma", "Freq_mod")
bisschen_tbl <- bisschen
colnames(bisschen_tbl) <- c("lemma", "Freq_bisschen")
# join dataframes
idee_tbl <- left_join(idee_tbl, decow_sum)
fuenk_tbl <- left_join(fuenk_tbl, decow_sum)
handvoll_tbl <- left_join(handvoll_tbl, decow_sum)
tack_tbl <- left_join(tack_tbl, decow_sum)
tick_tbl <- left_join(tick_tbl, decow_sum)
zack_tbl <- left_join(zack_tbl, decow_sum)
spur_tbl <- left_join(spur_tbl, decow_sum)
hauch_tbl <- left_join(hauch_tbl, decow_sum)
quaentchen_tbl <- left_join(quaentchen_tbl, decow_sum)
bisschen_tbl <- left_join(bisschen_tbl, decow_sum)
# replace NAs by 0
idee_tbl <- replace_na(idee_tbl, list(Freq_mod = 0, Freq = 0))
fuenk_tbl <- replace_na(fuenk_tbl, list(Freq_mod = 0, Freq = 0))
handvoll_tbl <- replace_na(handvoll_tbl, list(Freq_mod = 0, Freq = 0))
tack_tbl <- replace_na(tack_tbl, list(Freq_mod = 0, Freq = 0))
tick_tbl <- replace_na(tick_tbl, list(Freq_mod = 0, Freq = 0))
zack_tbl <- replace_na(zack_tbl, list(Freq_mod = 0, Freq = 0))
hauch_tbl <- replace_na(hauch_tbl, list(Freq_mod = 0, Freq = 0))
spur_tbl <- replace_na(spur_tbl, list(Freq_mod = 0, Freq = 0))
quaentchen_tbl <- replace_na(quaentchen_tbl, list(Freq_mod = 0, Freq = 0))
bisschen_tbl <- replace_na(bisschen_tbl, list(Freq_bisschen = 0, Freq = 0))
# reomove cases where cxn frequency is bigger than
# corpus frequency
idee_tbl <- idee_tbl[which(idee_tbl$Freq_mod <= idee_tbl$Freq),]
fuenk_tbl <- fuenk_tbl[which(fuenk_tbl$Freq_mod <= fuenk_tbl$Freq),]
handvoll_tbl <- handvoll_tbl[which(handvoll_tbl$Freq_mod <= handvoll_tbl$Freq),]
tack_tbl <- tack_tbl[which(tack_tbl$Freq_mod <= tack_tbl$Freq),]
tick_tbl <- tick_tbl[which(tick_tbl$Freq_mod <= tick_tbl$Freq),]
zack_tbl <- zack_tbl[which(zack_tbl$Freq_mod <= zack_tbl$Freq),]
spur_tbl <- spur_tbl[which(spur_tbl$Freq_mod <= spur_tbl$Freq),]
hauch_tbl <- hauch_tbl[which(hauch_tbl$Freq_mod <= hauch_tbl$Freq),]
quaentchen_tbl <- quaentchen_tbl[which(quaentchen_tbl$Freq_mod <= quaentchen_tbl$Freq),]
bisschen_tbl <- bisschen_tbl[which(bisschen_tbl$Freq_bisschen <= bisschen_tbl$Freq),]
col_idee <- collex(idee_tbl,
corpsize =
sum(pos_tbl[grep("ADJ.*", pos_tbl$pos),]$Freq))# %>%  write_excel_csv("idee_collex.csv")
col_fuenk <- collex(fuenk_tbl,
corpsize = sum(pos_tbl$Freq)) # %>% write_excel_csv("fuenkchen_collex.csv")
col_handvoll <- collex(handvoll_tbl,
corpsize = sum(pos_tbl$Freq)) # %>% write_csv("handvoll_collex.csv")
col_tack <- collex(tack_tbl,
corpsize = sum(pos_tbl$Freq)) # %>% write_csv("tack_collex.csv")
col_tick <- collex(tick_tbl,
corpsize = sum(pos_tbl$Freq)) # %>% write_csv("tick_collex.csv")
col_zack <- collex(zack_tbl,
corpsize = sum(pos_tbl$Freq)) # %>% write_csv("zack_collex.csv")
col_spur <- collex(spur_tbl,
corpsize = sum(pos_tbl$Freq)) # %>% write_csv("spur_collex.csv")
col_hauch <- collex(hauch_tbl,
corpsize = sum(pos_tbl$Freq)) # %>% write_csv("hauch_collex.csv")
col_quaentchen <- collex(quaentchen_tbl,
corpsize = sum(pos_tbl$Freq)) # %>% write_csv("quaentchen_collex.csv")
col_bisschen <- collex(as.data.frame(bisschen_tbl),
corpsize = sum(pos_tbl$Freq)) # %>% write_csv("bisschen_collex.csv")
bisschen_tbl
pos_tbl
pos_tbl$Freq
bisschen_tbl
str(bisschen_tbl)
bisschen_tbl
col_bisschen <- collex(as.data.frame(bisschen_tbl[,1:2]),
corpsize = sum(pos_tbl$Freq)) # %>% write_csv("bisschen_collex.csv")
col_bisschen <- collex(as.data.frame(bisschen_tbl[,c(1:2)]),
corpsize = sum(pos_tbl$Freq)) # %>% write_csv("bisschen_collex.csv")
bisschen_tbl[,c(1:2)]
col_bisschen <- collex(as.data.frame(bisschen_tbl),
corpsize = sum(pos_tbl$Freq)) # %>% write_csv("bisschen_collex.csv")
?collex
quaentchen_tbl
quaentchen_tbl %>% head()
bisschen_tbl
bisschen_tbl$Freq_bisschen <- as.numeric(bisschen_tbl$Freq_bisschen)
col_bisschen <- collex(as.data.frame(bisschen_tbl),
corpsize = sum(pos_tbl$Freq)) # %>% write_csv("bisschen_collex.csv")
# omit items in which observed frequency in cxn is
# larger than corpus frequency
which(bisschen_tbl$Freq_bisschen > bisschen_tbl$Freq)
# omit items in which observed frequency in cxn is
# larger than corpus frequency
bisschen_tbl[-which(bisschen_tbl$Freq_bisschen > bisschen_tbl$Freq),]
# omit items in which observed frequency in cxn is
# larger than corpus frequency
bisschen_tbl1 <- bisschen_tbl[-which(bisschen_tbl$Freq_bisschen > bisschen_tbl$Freq),]
col_bisschen <- collex(as.data.frame(bisschen_tbl1),
corpsize = sum(pos_tbl$Freq)) # %>% write_csv("bisschen_collex.csv")
links <- rbind(
col_idee %>% select(COLLEX, COLL.STR.LOGL) %>% mutate(LEX = "eine Idee") ,
col_handvoll %>% select(COLLEX, COLL.STR.LOGL) %>% mutate(LEX = "eine Handvoll") ,
col_fuenk %>% select(COLLEX, COLL.STR.LOGL) %>% mutate(LEX = "ein Fünkchen") ,
col_tack %>% select(COLLEX, COLL.STR.LOGL) %>% mutate(LEX = "ein Tacken"),
col_tick %>% select(COLLEX, COLL.STR.LOGL) %>% mutate(LEX = "ein Tick"),
col_zack %>% select(COLLEX, COLL.STR.LOGL) %>% mutate(LEX = "ein Zacken"),
col_hauch %>% select(COLLEX, COLL.STR.LOGL) %>% mutate(LEX = "ein Hauch"),
col_spur %>% select(COLLEX, COLL.STR.LOGL) %>% mutate(LEX = "eine Spur"),
col_quaentchen %>% select(COLLEX, COLL.STR.LOGL) %>% mutate(LEX = "ein Quäntchen"),
col_bisschen %>% select(COLLEX, COLL.STR.LOGL) %>% mutate(LEX = "ein bisschen") ) %>%
mutate(edge_type = LEX) %>%
group_by(LEX) %>%
slice(1:100) %>%
ungroup()
# reorder columns
links <- links[,c(3,1,2,4)] %>%
arrange(edge_type)
# create dataframes for links and nodes
nodes_LEX = data.frame(links$LEX) %>%
distinct() %>%
rename(name = links.LEX) %>%
mutate(node_type = name) %>%
mutate(node_size = 10) %>%
mutate(text_size = 100) %>%
mutate(text_fontface = "bold") %>%
mutate(shape = "circle") %>%
mutate(label = name)
nodes_COLLEX = data.frame(links$COLLEX) %>%
distinct() %>%
rename(name = links.COLLEX) %>%
mutate(node_type = "COLLEX") %>%
mutate(node_size = 1.5) %>%
mutate(text_size = 1) %>%
mutate(text_fontface = "plain") %>%
mutate(label = NA)
nodes_all = bind_rows(nodes_LEX, nodes_COLLEX) %>%
arrange(node_type)
# plot
col_graph <- graph_from_data_frame(links, nodes_all, directed = F)
set.seed(1995)
# used "kk" layout because it is less spread out
ggraph(col_graph, layout = "kk") +
geom_edge_link(aes(color = edge_type), show.legend = FALSE,
end_cap = circle(.07, 'inches')) +
scale_edge_color_manual(values = c("#FF0000", "#A7D547", "#FFA500", "#00FFFF",
"#FF00FF", "#00BFFF", "#008000",  "#CDAD5A", "#00FF00", "#AD7A44")) +
geom_node_point(aes(color = node_type, size = node_size), show.legend = FALSE) +
scale_color_manual(values = c("#000000", "#FF0000", "#A7D547", "#FFA500", "#00FFFF",
"#FF00FF", "#00BFFF", "#008000",  "#CDAD5A", "#00FF00", "#AD7A44")) +
geom_node_text(aes(label = label, size = text_size, fontface = text_fontface), vjust = 1, hjust = 1, show.legend = FALSE) +
theme_void()
